{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38816bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- Deep_Ensemble_Train.py -*-\n",
    "\"\"\"\n",
    "Created Oct 2020\n",
    "Amended Nov 2023 for Deep Ensemble\n",
    "\n",
    "@author: Timothy E H Allen / Alistair M Middleton / Adapted by Arndt Wallmann\n",
    "\"\"\"\n",
    "#%%\n",
    "\n",
    "# Import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v2 as tf\n",
    "# import tensorflow_probability as tfp # No longer needed\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os # For saving ensemble models\n",
    "\n",
    "tf.enable_v2_behavior()\n",
    "# tfd = tfp.distributions # No longer needed\n",
    "\n",
    "# Define inputs and variables\n",
    "receptor = \"AR\"\n",
    "input_data_a = \"/content/drive/My Drive/Training_Sets/\" + receptor + \" fingerprint.csv\"\n",
    "input_data_b = \"/content/drive/My Drive/Test_Sets/\" + receptor + \" fingerprint.csv\"\n",
    "rng_1 = 1989\n",
    "rng_2 = 2020\n",
    "validation_proportion = 0.25\n",
    "neurons = 10\n",
    "hidden_layers = 2\n",
    "LR = 0.01\n",
    "epochs = 100\n",
    "batch_size= 100\n",
    "ensemble_size = 5 # <<< Number of models in the ensemble\n",
    "model_base_path = \"/content/drive/My Drive/Models/\" + receptor + \"_ensemble_predictor\" # Base path for saving\n",
    "\n",
    "# Ensure model directory exists\n",
    "os.makedirs(model_base_path, exist_ok=True)\n",
    "\n",
    "def read_dataset(input_data):\n",
    "    df = pd.read_csv(input_data)\n",
    "    # Assuming fingerprints are first 10000 columns, adjust if different\n",
    "    X = df[df.columns[0:10000]].values.astype(np.float32) # Ensure float32 for TF\n",
    "    Y = df[df.columns[10000]].values.astype(np.float32) # Ensure float32 for TF\n",
    "    return X, Y\n",
    "\n",
    "# Load and shuffle data and make training and validation sets\n",
    "X, Y = read_dataset(input_data_a)\n",
    "test_x, test_y = read_dataset(input_data_b)\n",
    "X, Y = shuffle(X, Y, random_state=rng_1)\n",
    "train_x, validation_x, train_y, validation_y = train_test_split(X, Y, test_size=validation_proportion, random_state=rng_2)\n",
    "\n",
    "# --- BNN Specific kl_loss_weight removed ---\n",
    "# kl_loss_weight = 1 / train_x.shape[0] # Not needed for Deep Ensemble\n",
    "\n",
    "# Inspect the shape of the training and test data\n",
    "print(\"Dimensionality of data:\")\n",
    "print(\"Train x shape =\", train_x.shape, \"dtype =\", train_x.dtype)\n",
    "print(\"Train y shape =\", train_y.shape, \"dtype =\", train_y.dtype)\n",
    "print(\"Validation x shape =\", validation_x.shape, \"dtype =\", validation_x.dtype)\n",
    "print(\"Validation y shape =\", validation_y.shape, \"dtype =\", validation_y.dtype)\n",
    "print(\"Test x shape =\", test_x.shape, \"dtype =\", test_x.dtype)\n",
    "print(\"Test y shape =\", test_y.shape, \"dtype =\", test_y.dtype)\n",
    "\n",
    "# --- BNN posterior/prior functions removed ---\n",
    "# def posterior_mean_field(...): ...\n",
    "# def prior_not_trainable(...): ...\n",
    "\n",
    "# --- BNN negloglik removed, using standard 'mse' loss ---\n",
    "# def negloglik(y, rv_y): ...\n",
    "\n",
    "# --- Define the standard deterministic model architecture ---\n",
    "def create_deterministic_model(input_shape, neurons, hidden_layers):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=input_shape)) # Explicit Input Layer\n",
    "\n",
    "    if hidden_layers == 1:\n",
    "        model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(1)) # Output layer for regression\n",
    "\n",
    "    elif hidden_layers == 2:\n",
    "        model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(1)) # Output layer\n",
    "\n",
    "    elif hidden_layers == 3:\n",
    "        model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(1)) # Output layer\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Number of hidden layers outside this model scope, please choose 1, 2, or 3\")\n",
    "\n",
    "    model.compile(optimizer=tf.optimizers.Adam(learning_rate=LR), loss='mse', metrics=['mse', 'mae']) # Using MSE loss\n",
    "    return model\n",
    "\n",
    "# --- Train the ensemble ---\n",
    "ensemble_models = []\n",
    "histories = [] # Store history of each model\n",
    "\n",
    "input_shape = (train_x.shape[1],) # Define input shape based on data\n",
    "\n",
    "print(f\"\\n--- Training Deep Ensemble ({ensemble_size} members) ---\")\n",
    "for i in range(ensemble_size):\n",
    "    print(f\"\\nTraining Model {i+1}/{ensemble_size}\")\n",
    "    # Create a new instance for each ensemble member\n",
    "    model = create_deterministic_model(input_shape, neurons, hidden_layers)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_x, train_y,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(validation_x, validation_y),\n",
    "                        verbose=1) # Verbose set to 1 to see progress per model\n",
    "\n",
    "    histories.append(history)\n",
    "    ensemble_models.append(model)\n",
    "\n",
    "    # Save each model individually\n",
    "    member_model_path = os.path.join(model_base_path, f\"member_{i}\")\n",
    "    model.save(member_model_path, save_format=\"tf\")\n",
    "    print(f\"Model {i+1} saved to {member_model_path}\")\n",
    "\n",
    "print(\"\\n--- Ensemble Training Complete ---\")\n",
    "\n",
    "# --- Plot history of loss/metrics for the *last* trained model as an example ---\n",
    "# (Alternatively, average histories or plot all)\n",
    "last_history = histories[-1]\n",
    "print(\"\\n--- Plotting metrics for the last trained model ---\")\n",
    "\n",
    "# Plot history of loss values\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(last_history.history['loss'])\n",
    "plt.plot(last_history.history['val_loss'])\n",
    "plt.title(f'Model {ensemble_size} Loss')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot history of MAE values (using 'mae' metric added during compile)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(last_history.history['mae'])\n",
    "plt.plot(last_history.history['val_mae'])\n",
    "plt.title(f'Model {ensemble_size} MAE')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Ensemble Prediction and Evaluation ---\n",
    "\n",
    "def predict_ensemble(models, x_data):\n",
    "    \"\"\"Generates predictions from each model in the ensemble.\"\"\"\n",
    "    all_preds = []\n",
    "    for model in tqdm.tqdm(models, desc=\"Predicting with Ensemble\"):\n",
    "        # Predict returns shape (n_samples, 1), squeeze to (n_samples,) if needed,\n",
    "        # but stacking handles (n_samples, 1) correctly for hstack.\n",
    "        y_pred = model.predict(x_data)\n",
    "        all_preds.append(y_pred)\n",
    "    # Stack predictions along a new axis (axis=1): shape becomes (n_samples, n_models)\n",
    "    return np.hstack(all_preds) # Use hstack if preds are (N,1) -> (N, n_models)\n",
    "\n",
    "# Calculate test data outputs\n",
    "print(\"\\n--- Evaluating on Test Set ---\")\n",
    "y_preds_ensemble_test = predict_ensemble(ensemble_models, test_x)\n",
    "y_mean_test = np.mean(y_preds_ensemble_test, axis=1)\n",
    "y_sigma_test = np.std(y_preds_ensemble_test, axis=1) # Uncertainty estimate\n",
    "\n",
    "# Plot experimental vs predicted values for test data\n",
    "plt.figure()\n",
    "plt.scatter(test_y, y_mean_test, marker='o', alpha=0.5)\n",
    "# Add y=x line for reference\n",
    "min_val = min(test_y.min(), y_mean_test.min())\n",
    "max_val = max(test_y.max(), y_mean_test.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='y=x')\n",
    "plt.title('Test Set: Experimental vs. Predicted (Ensemble Mean)')\n",
    "plt.xlabel('Experimental Value')\n",
    "plt.ylabel('Predicted Value (Mean)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot prediction uncertainty (optional)\n",
    "plt.figure()\n",
    "plt.scatter(y_mean_test, y_sigma_test, marker='o', alpha=0.5)\n",
    "plt.title('Test Set: Prediction Uncertainty (Ensemble Std Dev)')\n",
    "plt.xlabel('Predicted Value (Mean)')\n",
    "plt.ylabel('Prediction Uncertainty (Std Dev)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate and print mean absolute error values for train, validation, and test sets\n",
    "print(\"\\n--- Evaluating on Training Set ---\")\n",
    "y_preds_ensemble_train = predict_ensemble(ensemble_models, train_x)\n",
    "y_mean_train = np.mean(y_preds_ensemble_train, axis=1)\n",
    "\n",
    "print(\"\\n--- Evaluating on Validation Set ---\")\n",
    "y_preds_ensemble_validation = predict_ensemble(ensemble_models, validation_x)\n",
    "y_mean_validation = np.mean(y_preds_ensemble_validation, axis=1)\n",
    "\n",
    "print(\"\\n--- MAE Results ---\")\n",
    "print(f\"Training Set MAE:   {mean_absolute_error(train_y, y_mean_train):.4f}\")\n",
    "print(f\"Validation Set MAE: {mean_absolute_error(validation_y, y_mean_validation):.4f}\")\n",
    "print(f\"Test Set MAE:       {mean_absolute_error(test_y, y_mean_test):.4f}\")\n",
    "\n",
    "\n",
    "# End the cycle (optional, good practice in scripts)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Endgame\n",
    "print(\"\\nEND\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
