# -*- Deep_Ensemble_Train.py -*-
"""
Created Oct 2023

@author: Arndt Wallmann
"""
#%%

# Import modules
import numpy as np
import matplotlib.pyplot as plt
import tensorflow.compat.v2 as tf
import tqdm
import pandas as pd
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
import random
import seaborn as sns

# Define inputs and variables (renamed)
target_receptor = "AR"
train_data_path = "/content/drive/My Drive/Training_Sets/" + target_receptor + " fingerprint.csv"
test_data_path = "/content/drive/My Drive/Test_Sets/" + target_receptor + " fingerprint.csv"
random_seed_train = 1989
random_seed_val = 2020
val_split_ratio = 0.25
num_neurons = 10
hidden_layer_count = 2
learning_rate = 0.01
num_epochs = 100
batch_size = 100
model_dir = "/content/drive/My Drive/Models/" + target_receptor + "_deep_ensemble_predictor"
ensemble_size = 5  # Number of models in the ensemble

# Load and shuffle data and create training and validation sets (renamed variables)
def load_dataset(data_path):
    df = pd.read_csv(data_path)
    X = df[df.columns[0:10000]].values
    Y = df[df.columns[10000]]
    return X, Y

X_train_full, y_train_full = load_dataset(train_data_path)
X_test, y_test = load_dataset(test_data_path)

X_train_full, y_train_full = shuffle(X_train_full, y_train_full, random_state=random_seed_train)
X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=val_split_ratio, random_state=random_seed_val)

print("Dataset dimensions:")
print("Train X shape =", X_train.shape)
print("Train y shape =", y_train.shape)
print("Validation X shape =", X_val.shape)
print("Validation y shape =", y_val.shape)
print("Test X shape =", X_test.shape)
print("Test y shape =", y_test.shape)


# Define the model architecture for deep ensemble (renamed)
def create_deep_ensemble_model():
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(num_neurons, activation='relu', input_shape=(X_train.shape[1],)),
        tf.keras.layers.Dense(num_neurons, activation='relu'),
        tf.keras.layers.Dense(1)  # Regression output layer
    ])
    model.compile(optimizer=tf.optimizers.Adam(learning_rate=learning_rate), loss='mse', metrics=['mse'])
    return model

# Train ensemble of models (renamed)
deep_ensemble_models = [create_deep_ensemble_model() for _ in range(ensemble_size)]

for idx, model in enumerate(deep_ensemble_models):
    print(f"Training model {idx+1}/{ensemble_size} in the ensemble")
    model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_val, y_val), verbose=True)

# Predict using the ensemble (renamed)
y_pred_list = [model.predict(X_test) for model in deep_ensemble_models]
y_preds = np.array(y_pred_list)

# Mean and variance of ensemble predictions (renamed)
y_mean_ensemble = np.mean(y_preds, axis=0)
y_variance_ensemble = np.var(y_preds, axis=0)

# Plot experimental vs predicted values for the test data (renamed)
plt.figure()
plt.scatter(y_test, y_mean_ensemble, marker='o')
plt.title('Experimental vs Predicted (Test Data)')
plt.xlabel('True Values')
plt.ylabel('Predicted Values (Mean)')
plt.show()

# Calculate and print mean absolute error for the test set (renamed)
mae_test_ensemble = mean_absolute_error(y_test, y_mean_ensemble)
print("Test Set MAE for Deep Ensemble:")
print(mae_test_ensemble)

# Plot the uncertainty (standard deviation) of ensemble predictions (renamed)
plt.figure()
plt.scatter(y_test, y_variance_ensemble, marker='o')
plt.title('Predicted Uncertainty (Test Data)')
plt.xlabel('True Values')
plt.ylabel('Prediction Variance (Uncertainty)')
plt.show()

# End the cycle and clear session (renamed)
tf.keras.backend.clear_session()
print("Deep Ensemble Training Completed")
